"""
Retrieval ì •í™•ë„ í‰ê°€ ìŠ¤í¬ë¦½íŠ¸
- eval_set.json ê¸°ë°˜ìœ¼ë¡œ ê²€ìƒ‰ Hit Rate ì¸¡ì •
- ì •ë‹µ(ground_truth)ì— í¬í•¨ëœ ë²•ë ¹ ì¡°í•­ì´ ê²€ìƒ‰ ê²°ê³¼ì— ìˆëŠ”ì§€ í™•ì¸
"""

import json
import re
import sys
from pathlib import Path
from typing import List, Dict, Optional
from dataclasses import dataclass

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ pathì— ì¶”ê°€
sys.path.insert(0, str(Path(__file__).parent / "src"))

from vectorstore import VectorStore


@dataclass
class EvalSample:
    """í‰ê°€ ìƒ˜í”Œ"""
    question: str
    ground_truth: str
    target_law: str  # ë²•ë ¹ëª…+ì¡°í•­ (ì˜ˆ: "í˜•ë²•ì œ17ì¡°")
    target_article: str  # ì¡°í•­ë§Œ (ì˜ˆ: "17ì¡°")
    doc_type: str
    doc_id: str


def load_eval_set(eval_set_path: str = "eval_set_retrieval.json") -> List[EvalSample]:
    """
    eval_set_retrieval.json íŒŒì¼ì„ ë¡œë“œí•˜ê³  í‰ê°€ ìƒ˜í”Œ ìƒì„±
    (law_name, article í•„ë“œê°€ ì´ë¯¸ ì¶”ì¶œë˜ì–´ ìˆëŠ” ë°ì´í„°ì…‹ ì‚¬ìš©)

    Args:
        eval_set_path: eval_set_retrieval.json íŒŒì¼ ê²½ë¡œ
    """
    print(f"ğŸ“‚ í‰ê°€ ë°ì´í„° ë¡œë“œ ì¤‘: {eval_set_path}")

    with open(eval_set_path, 'r', encoding='utf-8') as f:
        data = json.load(f)

    items = data.get("items", [])
    samples = []
    skipped = 0

    for item in items:
        question = item.get("question", "")
        ground_truth = item.get("ground_truth", "")
        doc_type = item.get("doc_type", "")
        doc_id = item.get("doc_id", "")
        law_name = item.get("law_name", "")
        article = item.get("article", "")

        if not question or not law_name or not article:
            skipped += 1
            continue

        # law_name + ì œ + article í˜•íƒœë¡œ target_law ìƒì„±
        target_law = f"{law_name}ì œ{article}"
        target_article = f"ì œ{article}"  # ì¡°í•­ë§Œ (ì˜ˆ: "ì œ17ì¡°")

        samples.append(EvalSample(
            question=question,
            ground_truth=ground_truth,
            target_law=target_law,
            target_article=target_article,
            doc_type=doc_type,
            doc_id=doc_id
        ))

    print(f"  ì´ {len(items)}ê°œ ì¤‘ {len(samples)}ê°œ í‰ê°€ ê°€ëŠ¥ (ìŠ¤í‚µ: {skipped}ê°œ)")
    return samples


def run_evaluation(
    vectorstore: VectorStore,
    samples: List[EvalSample],
    top_k: int = 5,
    verbose: bool = True
) -> Dict:
    """
    Retrieval í‰ê°€ ì‹¤í–‰

    Args:
        vectorstore: VectorStore ì¸ìŠ¤í„´ìŠ¤
        samples: í‰ê°€ ìƒ˜í”Œ ë¦¬ìŠ¤íŠ¸
        top_k: ê²€ìƒ‰í•  ë¬¸ì„œ ê°œìˆ˜
        verbose: ì˜¤ë‹µ ìƒì„¸ ì¶œë ¥ ì—¬ë¶€
    """
    print(f"\n{'='*50}")
    print(f"ğŸš€ Retrieval í‰ê°€ ì‹œì‘ (top_k={top_k})")
    print(f"{'='*50}\n")

    total_count = len(samples)
    correct_count = 0
    errors = []

    # doc_typeë³„ í†µê³„
    type_stats = {}

    for i, sample in enumerate(samples):
        # ê²€ìƒ‰ ìˆ˜í–‰
        try:
            results = vectorstore.search(sample.question, n_results=top_k)
        except Exception as e:
            print(f"âŒ [ERROR] ë¬¸ì œ {i+1} ê²€ìƒ‰ ì¤‘ ì—ëŸ¬: {e}")
            continue

        # Hit ì—¬ë¶€ í™•ì¸
        # ChromaDB ì²­í¬ì—ëŠ” ë²•ë ¹ëª…ì´ ì—†ì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì¡°í•­ ë²ˆí˜¸ë¡œ ë§¤ì¹­
        is_hit = False
        hit_doc_idx = -1
        retrieved_contents = []

        for idx, doc in enumerate(results):
            content = doc.get("content", "")

            # contentì—ì„œ "ì œNì¡°(ì œëª©)" íŒ¨í„´ ì¶”ì¶œ
            article_match = re.search(r"(ì œ\d+ì¡°(?:ì˜\d+)?)\s*\(([^)]+)\)", content)
            if article_match:
                article_info = f"{article_match.group(1)}({article_match.group(2)})"
            else:
                # ì œNì¡°ë§Œì´ë¼ë„ ì¶”ì¶œ
                simple_match = re.search(r"(ì œ\d+ì¡°(?:ì˜\d+)?)", content)
                article_info = simple_match.group(1) if simple_match else "ì¡°í•­ì—†ìŒ"

            # ì¡°í•­ ì •ë³´ + ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°
            preview = f"[{article_info}] {content[:50]}..."
            retrieved_contents.append(preview)

            # ì—„ê²© ë§¤ì¹­: "ì œNì¡°(ì œëª©)" ë˜ëŠ” "ì œNì¡° â‘ " í˜•íƒœë¡œ ì¡°í•­ì´ ì‹œì‘í•˜ëŠ” ê²½ìš°ë§Œ ì¸ì •
            # ë‹¨ìˆœíˆ "ì œ4ì¡°ì— ë”°ë¼..." ê°™ì€ ì°¸ì¡°ëŠ” ì œì™¸
            strict_pattern = rf"{re.escape(sample.target_article)}\s*[\(â‘ â‘¡â‘¢â‘£â‘¤â‘¥â‘¦â‘§â‘¨â‘©]"
            if not is_hit and re.search(strict_pattern, content):
                is_hit = True
                hit_doc_idx = idx

        # doc_typeë³„ í†µê³„ ì—…ë°ì´íŠ¸
        if sample.doc_type not in type_stats:
            type_stats[sample.doc_type] = {"total": 0, "correct": 0}
        type_stats[sample.doc_type]["total"] += 1

        if is_hit:
            correct_count += 1
            type_stats[sample.doc_type]["correct"] += 1
            if verbose:
                print(f"âœ… [ì •ë‹µ] ë¬¸ì œ {i+1} ({sample.doc_type})")
                print(f"   - ì§ˆë¬¸: {sample.question[:80]}...")
                print(f"   - ëª©í‘œ: {sample.target_law} (ë§¤ì¹­: {sample.target_article})")
                print(f"   - ê²€ìƒ‰ëœ ë¬¸ì„œë“¤:")
                for j, content in enumerate(retrieved_contents):
                    marker = "â­" if j == hit_doc_idx else "  "
                    print(f"     {marker}[{j+1}] {content}")
                print("-" * 50)
        else:
            errors.append({
                "index": i + 1,
                "question": sample.question,
                "target": sample.target_law,
                "doc_type": sample.doc_type,
                "retrieved": retrieved_contents
            })

            if verbose and len(errors) <= 10:  # ì²˜ìŒ 10ê°œë§Œ ì¶œë ¥
                print(f"âŒ [ì˜¤ë‹µ] ë¬¸ì œ {i+1} ({sample.doc_type})")
                print(f"   - ì§ˆë¬¸: {sample.question[:80]}...")
                print(f"   - ëª©í‘œ: {sample.target_law} (ë§¤ì¹­: {sample.target_article})")
                print(f"   - ê²€ìƒ‰ëœ ê²ƒ: {retrieved_contents[0] if retrieved_contents else 'None'}")
                print("-" * 50)

    # ê²°ê³¼ ê³„ì‚°
    accuracy = (correct_count / total_count) * 100 if total_count > 0 else 0

    # ìµœì¢… ë¦¬í¬íŠ¸
    print(f"\n{'='*50}")
    print(f"ğŸ“Š [ìµœì¢… ê²°ê³¼ ë¦¬í¬íŠ¸]")
    print(f"{'='*50}")
    print(f"ì´ í‰ê°€ ë¬¸ì œ ìˆ˜: {total_count}ê°œ")
    print(f"âœ… ì •ë‹µ (Hit): {correct_count}ê°œ")
    print(f"âŒ ì˜¤ë‹µ (Miss): {total_count - correct_count}ê°œ")
    print(f"ğŸ† Hit Rate @ {top_k}: {accuracy:.2f}%")

    # doc_typeë³„ ê²°ê³¼
    print(f"\nğŸ“ˆ [ìœ í˜•ë³„ Hit Rate]")
    for doc_type, stats in sorted(type_stats.items()):
        type_acc = (stats["correct"] / stats["total"]) * 100 if stats["total"] > 0 else 0
        print(f"  {doc_type}: {stats['correct']}/{stats['total']} ({type_acc:.1f}%)")

    print(f"{'='*50}")

    return {
        "total": total_count,
        "correct": correct_count,
        "errors": len(errors),
        "hit_rate": accuracy,
        "top_k": top_k,
        "type_stats": type_stats,
        "error_details": errors[:20]  # ì²˜ìŒ 20ê°œ ì˜¤ë‹µë§Œ ì €ì¥
    }


def save_results(results: Dict, output_path: str = "retrieval_eval_results.json"):
    """ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥"""
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    print(f"\nê²°ê³¼ ì €ì¥ë¨: {output_path}")


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="Retrieval í‰ê°€")
    parser.add_argument("--eval-set", type=str, default="eval_set_retrieval.json",
                        help="í‰ê°€ ë°ì´í„° ê²½ë¡œ (ê¸°ë³¸: eval_set_retrieval.json)")
    parser.add_argument("--top-k", type=int, default=3,
                        help="ê²€ìƒ‰í•  ë¬¸ì„œ ìˆ˜")
    parser.add_argument("--quiet", action="store_true",
                        help="ì˜¤ë‹µ ìƒì„¸ ì¶œë ¥ ì•ˆí•¨")
    parser.add_argument("--save", action="store_true",
                        help="ê²°ê³¼ë¥¼ JSONìœ¼ë¡œ ì €ì¥")
    args = parser.parse_args()

    samples = load_eval_set(args.eval_set)

    if not samples:
        print("í‰ê°€í•  ìƒ˜í”Œì´ ì—†ìŠµë‹ˆë‹¤.")
        sys.exit(1)

    print("\nğŸ”§ VectorStore ì´ˆê¸°í™” ì¤‘...")
    vs = VectorStore()

    results = run_evaluation(
        vectorstore=vs,
        samples=samples,
        top_k=args.top_k,
        verbose=not args.quiet
    )

    if args.save:
        save_results(results)
