"""
Justi-Q Streamlit í”„ë¡ íŠ¸ì—”ë“œ
í˜•ì‚¬ë²• RAG ì‹œìŠ¤í…œ ì›¹ ì¸í„°í˜ì´ìŠ¤
"""

import sys
import os
sys.path.append("src")

from dotenv import load_dotenv
load_dotenv()

# LangSmith ì„¤ì • (Streamlit ì„í¬íŠ¸ ì „ì— ì„¤ì •)
if os.getenv("LANGCHAIN_API_KEY"):
    os.environ["LANGCHAIN_TRACING_V2"] = "true"
    os.environ["LANGCHAIN_PROJECT"] = "justi-q"
    os.environ["LANGCHAIN_ENDPOINT"] = "https://api.smith.langchain.com"

import streamlit as st
from vectorstore import VectorStore
from rag_chain import RAGChain

# âœ… LangGraph workflow ì¶”ê°€
from langgraph_workflow import run_workflow


# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="Justi-Q í˜•ì‚¬ë²• AI",
    page_icon="âš–ï¸",
    layout="wide"
)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
@st.cache_resource
def load_rag_system():
    """RAG ì‹œìŠ¤í…œ ë¡œë“œ (ìºì‹±)"""
    vectorstore = VectorStore(
        collection_name="legal_documents",
        persist_dir="chroma_db"
    )
    rag_chain = RAGChain(vectorstore)
    return rag_chain


def main():
    # í—¤ë”
    st.title("âš–ï¸ Justi-Q í˜•ì‚¬ë²• AI")
    st.markdown("í˜•ì‚¬ë²• ê´€ë ¨ ì§ˆë¬¸ì— íŒë¡€ì™€ ë²•ë ¹ì„ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•´ë“œë¦½ë‹ˆë‹¤.")
    st.divider()

    # ì‚¬ì´ë“œë°”
    with st.sidebar:
        st.header("ì„¤ì •")
        n_results = st.slider("ê²€ìƒ‰ ë¬¸ì„œ ìˆ˜", min_value=3, max_value=10, value=5)

        st.divider()
        st.header("ì •ë³´")
        st.markdown("""
        **ë°ì´í„° ì¶œì²˜:**
        - íŒë¡€ 750ê±´
        - ê²°ì •ë¬¸ 294ê±´
        - ë²•ë ¹ 898ê±´
        - í•´ì„ 58ê±´

        **ëª¨ë¸:**
        - ì„ë² ë”©: multilingual-e5-large
        - LLM: Llama 3.3 70B
        """)

    # RAG ì‹œìŠ¤í…œ ë¡œë“œ
    try:
        rag = load_rag_system()
    except ValueError as e:
        if "OPENROUTER_API_KEY" in str(e):
            st.error("ì‹œìŠ¤í…œ ë¡œë“œ ì‹¤íŒ¨: OPENROUTER_API_KEY í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
            st.info("**Streamlit Cloud ë°°í¬ ì‹œ:** Settings > Secretsì—ì„œ `OPENROUTER_API_KEY = \"your_key\"` ì¶”ê°€")
        else:
            st.error(f"ì‹œìŠ¤í…œ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return
    except Exception as e:
        error_msg = str(e)
        st.error(f"ì‹œìŠ¤í…œ ë¡œë“œ ì‹¤íŒ¨: {error_msg}")
        st.info("ë¨¼ì € `python main.py --index` ë¡œ ì¸ë±ì‹±ì„ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
        return

    def _one_line_summary(src: dict, max_len: int = 70) -> str:
        # titleì´ ìˆìœ¼ë©´ title ìš°ì„ , ì—†ìœ¼ë©´ ë³¸ë¬¸ ì²« ì¤„/ì•ë¶€ë¶„
        title = (src.get("title") or "").strip()
        if title:
            s = title
        else:
            content = (src.get("content") or "").strip()
            first_line = content.splitlines()[0].strip() if content else ""
            s = first_line if first_line else content[:max_len]
        s = s.replace("\n", " ").strip()
        return (s[:max_len] + "â€¦") if len(s) > max_len else s

    def _render_sources(sources: list, key_prefix: str):
        if not sources:
            return
        st.markdown(f"ğŸ“š ì°¸ê³  ë¬¸ì„œ ({len(sources)}ê±´)")
        for i, src in enumerate(sources, 1):
            doc_type = src.get("type", "ë¬¸ì„œ")
            doc_id = src.get("doc_id", "unknown")
            sim = None
            if src.get("distance") is not None:
                sim = 1 - float(src["distance"])
            summary = _one_line_summary(src)

            # í•œ ì¤„ ìš”ì•½(í•­ëª©) + í´ë¦­í•˜ë©´ ë³¸ë¬¸ì´ í¼ì³ì§€ëŠ” í† ê¸€
            header = f"{i}. [{doc_type}] {doc_id} â€” {summary}"
            if sim is not None:
                header += f" (ìœ ì‚¬ë„: {sim:.2%})"

            with st.expander(header, expanded=False):
                # ì½ê¸° ì „ìš© ë³¸ë¬¸ í‘œì‹œ: textarea ëŒ€ì‹  markdown/code ì‚¬ìš©
                content = src.get("content", "")
                if content:
                    st.code(content, language=None)
                else:
                    st.caption("ë³¸ë¬¸ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.")


    # ì±„íŒ… íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # ì´ì „ ë©”ì‹œì§€ í‘œì‹œ
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
            if "sources" in message:
                with st.expander("ğŸ“š ì°¸ê³  ë¬¸ì„œ"):
                    for src in message["sources"]:
                        st.markdown(f"- **[{src['type']}]** {src['doc_id']}")

            # âœ… (ì„ íƒ) grounded/issues í‘œì‹œìš©
            if message.get("grounded") is False and message.get("issues"):
                with st.expander("âš ï¸ ê·¼ê±° ê²€ì¦ ì´ìŠˆ"):
                    for it in message["issues"]:
                        st.markdown(f"- {it}")

    # ì‚¬ìš©ì ì…ë ¥
    if prompt := st.chat_input("í˜•ì‚¬ë²• ê´€ë ¨ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”..."):
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        # AI ì‘ë‹µ ìƒì„±
        with st.chat_message("assistant"):
            with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
                # âœ… ì—¬ê¸°ë§Œ í•µì‹¬ ë³€ê²½: rag.query() -> LangGraph run_workflow()
                final_state = run_workflow(
                    question=prompt,
                    vectorstore=rag.vectorstore,   # RAGChainì´ ê°€ì§„ vectorstore ì¬ì‚¬ìš©
                    rag_chain=rag,
                    n_results=n_results,
                    filter_type=None,
                )

            final_text = final_state.get("final", "")
            st.markdown(final_text)

            # âœ… ì°¸ê³  ë¬¸ì„œ í‘œì‹œ (LangGraph state.documents ê¸°ë°˜)
            docs = final_state.get("documents") or []
            sources = []
            for d in docs:
                md = d.get("metadata", {}) or {}
                sources.append({
                    "doc_id": md.get("doc_id", "unknown"),
                    "type": md.get("type_name", "ë¬¸ì„œ"),
                    "distance": d.get("distance", None),
                })

            with st.expander("ğŸ“š ì°¸ê³  ë¬¸ì„œ"):
                if not sources:
                    st.markdown("- (ì—†ìŒ)")
                else:
                    for src in sources:
                        dist = src.get("distance")
                        if isinstance(dist, float):
                            st.markdown(f"- **[{src['type']}]** {src['doc_id']} (dist: {dist:.4f})")
                        else:
                            st.markdown(f"- **[{src['type']}]** {src['doc_id']}")

            # âœ… grounded / issues í‘œì‹œ
            grounded = final_state.get("grounded", None)
            issues = final_state.get("issues") or []
            if grounded is False:
                st.warning("ê·¼ê±° ê¸°ë°˜ ê²€ì¦ì—ì„œ ë¬¸ì œê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.")
                with st.expander("âš ï¸ ê·¼ê±° ê²€ì¦ ì´ìŠˆ"):
                    for it in issues:
                        st.markdown(f"- {it}")

        # ì–´ì‹œìŠ¤í„´íŠ¸ ë©”ì‹œì§€ ì €ì¥
        st.session_state.messages.append({
            "role": "assistant",
            "content": final_text,
            "sources": sources,
            "grounded": final_state.get("grounded", None),
            "issues": issues,
        })


if __name__ == "__main__":
    main()
